{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DPTxoJF_lV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYUJZtAE7pmq",
        "outputId": "3cb40383-f630-4f21-cebb-a1f184653487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Collecting unrar\n",
            "  Downloading unrar-0.4-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ],
      "source": [
        "# Import dependencies\n",
        "\n",
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install kaggle\n",
        "!pip install unrar\n",
        "!pip install patool\n",
        "import tensorflow as tf\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import os\n",
        "import patoolib\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNiR2G-qHxg6"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6fc2yMrHduU"
      },
      "outputs": [],
      "source": [
        "# Initialize paths\n",
        "data_dir = os.path.join(os.curdir, 'drive', 'MyDrive', 'Muvision', 'datasets', 'handwritten_math_symbols')\n",
        "model_dir = os.path.join(os.curdir, 'drive', 'MyDrive', 'Muvision', 'models')\n",
        "\n",
        "custom_model_path = os.path.join(model_dir, 'custom_model.h5')\n",
        "resnet_model_path = os.path.join(model_dir, 'resnet_model.h5')\n",
        "vgg19_model_path = os.path.join(model_dir, 'vgg19_model.h5')\n",
        "mobilenet_model_path = os.path.join(model_dir, 'mobilenet_model.h5')\n",
        "ensemble_model_path = os.path.join(model_dir, 'ensemble_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVLLtrVzO_UT"
      },
      "outputs": [],
      "source": [
        "# Initialize important variables\n",
        "classes = 19\n",
        "input_shape=(45,45,3)\n",
        "batch_size = 1\n",
        "image_size = (45, 45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWp7X9UPJgHW"
      },
      "source": [
        "## Preprocess the colors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLPtqNmMHSAb"
      },
      "outputs": [],
      "source": [
        "# Let's see what an individual image in the dataset looks like.\n",
        "sample_img_path = os.path.join(data_dir, '0', '10014.jpg')\n",
        "img = np.asarray(Image.open(sample_img_path))\n",
        "imgplot = plt.imshow(img)\n",
        "print(repr(img))\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAhuR1IfN3Vu"
      },
      "outputs": [],
      "source": [
        "# Since the images are already gray scale, we don't need to make any changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4yTIBDOJvMk"
      },
      "source": [
        "## Preprocess data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9PrDLT7Dafc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJbNBW8LFXA3"
      },
      "outputs": [],
      "source": [
        "data_set = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Muvision/datasets/handwritten_math_symbols', batch_size = batch_size, image_size = image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkqzgjG7IEGP"
      },
      "outputs": [],
      "source": [
        "# Normalize images\n",
        "data_set = data_set.map(lambda x,y: (x/255, y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data_set))"
      ],
      "metadata": {
        "id": "aP4gygV69AWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOVFdFmSMmoC"
      },
      "outputs": [],
      "source": [
        "# Allocate training, validation, and test sizes\n",
        "train_size = int(len(data_set)* .7)\n",
        "val_size = int(len(data_set)*.2)+1\n",
        "test_size = int(len(data_set)*.1)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbfMgfxcM3JB"
      },
      "outputs": [],
      "source": [
        "# Split up dataset into train, validation and test\n",
        "train = data_set.take(train_size)\n",
        "val = data_set.skip(train_size).take(val_size)\n",
        "test = data_set.skip(train_size + val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uAWBF3bxBTi"
      },
      "source": [
        "## Create Custom Model using Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkc5ozRCxMmh"
      },
      "outputs": [],
      "source": [
        "custom_model = models.Sequential(name='Custom_Model')\n",
        "\n",
        "# Convolutional base\n",
        "custom_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "custom_model.add(layers.MaxPooling2D((2, 2)))\n",
        "custom_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "custom_model.add(layers.MaxPooling2D((2, 2)))\n",
        "custom_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Dense layers\n",
        "custom_model.add(layers.Flatten())\n",
        "custom_model.add(layers.Dense(64, activation='relu'))\n",
        "custom_model.add(layers.Dense(classes, activation='softmax'))\n",
        "custom_model.summary()\n",
        "\n",
        "# The summary shows that the convolutional base has a (4, 4, 64) output, which\n",
        "#   is flattened into a (1024) shaped vector, and then sent through two Dense\n",
        "#   layers\n",
        "\n",
        "custom_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "custom_model_history = custom_model.fit(train, epochs=10,\n",
        "                         validation_data=val)\n",
        "\n",
        "custom_model.save(custom_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci4F0BLbA62T"
      },
      "outputs": [],
      "source": [
        "plt.plot(custom_model_history.history['accuracy'], label='accuracy')\n",
        "plt.plot(custom_model_history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = custom_model.evaluate(test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jLHDig8hGrS"
      },
      "source": [
        "## Create Model using Resnet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVZLejYThHdq",
        "outputId": "7fe80e3f-94ef-41ce-d8f3-4a992920f0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet_model = models.Sequential(name='Resnet_Model')\n",
        "\n",
        "resnet_pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "\n",
        "                   input_shape=input_shape,\n",
        "\n",
        "                   pooling='max',classes=classes,\n",
        "\n",
        "                   weights='imagenet')\n",
        "\n",
        "for each_layer in resnet_pretrained_model.layers:\n",
        "\n",
        "        each_layer.trainable=False\n",
        "\n",
        "resnet_model.add(resnet_pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXyHjfHxiWmS"
      },
      "outputs": [],
      "source": [
        "resnet_model.add(layers.Flatten())\n",
        "\n",
        "resnet_model.add(layers.Dense(512, activation='relu'))\n",
        "resnet_model.add(layers.Dense(classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ocwg282iXPl",
        "outputId": "ec175cd9-b553-4a26-a287-fae1b941e729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7049/7049 [==============================] - 426s 60ms/step - loss: 1.3445 - accuracy: 0.5795 - val_loss: 0.7877 - val_accuracy: 0.7444\n",
            "Epoch 2/10\n",
            "7049/7049 [==============================] - 411s 58ms/step - loss: 0.8693 - accuracy: 0.7153 - val_loss: 0.6582 - val_accuracy: 0.7881\n",
            "Epoch 3/10\n",
            "7049/7049 [==============================] - 411s 58ms/step - loss: 0.7243 - accuracy: 0.7666 - val_loss: 0.6750 - val_accuracy: 0.7841\n",
            "Epoch 4/10\n",
            "7049/7049 [==============================] - 415s 59ms/step - loss: 0.6475 - accuracy: 0.7885 - val_loss: 0.6463 - val_accuracy: 0.7896\n",
            "Epoch 5/10\n",
            "7049/7049 [==============================] - 407s 58ms/step - loss: 0.5963 - accuracy: 0.8071 - val_loss: 0.7565 - val_accuracy: 0.7906\n",
            "Epoch 6/10\n",
            "7049/7049 [==============================] - 401s 57ms/step - loss: 0.5612 - accuracy: 0.8173 - val_loss: 0.8775 - val_accuracy: 0.7464\n",
            "Epoch 7/10\n",
            "7049/7049 [==============================] - 396s 56ms/step - loss: 0.5209 - accuracy: 0.8323 - val_loss: 0.8999 - val_accuracy: 0.7434\n",
            "Epoch 8/10\n",
            "7049/7049 [==============================] - 401s 57ms/step - loss: 0.4945 - accuracy: 0.8418 - val_loss: 0.5766 - val_accuracy: 0.8268\n",
            "Epoch 9/10\n",
            "7049/7049 [==============================] - 400s 57ms/step - loss: 0.4770 - accuracy: 0.8465 - val_loss: 0.6189 - val_accuracy: 0.8213\n",
            "Epoch 10/10\n",
            "7049/7049 [==============================] - 397s 56ms/step - loss: 0.4530 - accuracy: 0.8500 - val_loss: 0.6568 - val_accuracy: 0.8065\n"
          ]
        }
      ],
      "source": [
        "resnet_model.compile(optimizer = optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "\n",
        "epochs = 10\n",
        "history = resnet_model.fit(train, validation_data=val, epochs=epochs)\n",
        "resnet_model.save(resnet_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "meRo2PWxiY_u"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "epochs_range= range(epochs)\n",
        "\n",
        "plt.plot( epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
        "\n",
        "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend(['train', 'validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SiBOhhbziax_"
      },
      "outputs": [],
      "source": [
        "#plotter_lib.show()\n",
        "\n",
        "plt.savefig('output-plot.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05exxZ78FTOH"
      },
      "source": [
        "## Create Model using VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YoNT2YT6FX8n"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tEPnt0EwFdji"
      },
      "outputs": [],
      "source": [
        "vgg19_model = models.Sequential(name='VGG19_Model')\n",
        "\n",
        "vgg19_pretrained_model= tf.keras.applications.VGG19(include_top=False,\n",
        "\n",
        "                   input_shape=input_shape,\n",
        "\n",
        "                   pooling='max',classes=classes,\n",
        "\n",
        "                   weights='imagenet')\n",
        "\n",
        "for each_layer in vgg19_pretrained_model.layers:\n",
        "        each_layer.trainable=False\n",
        "\n",
        "vgg19_model.add(vgg19_pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Amd07fJYKPv2"
      },
      "outputs": [],
      "source": [
        "vgg19_model.add(layers.Flatten())\n",
        "\n",
        "vgg19_model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "vgg19_model.add(layers.Dense(classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sywhMHGQKXf9"
      },
      "outputs": [],
      "source": [
        "vgg19_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "\n",
        "epochs = 8\n",
        "try:\n",
        "  history = vgg19_model.fit(train, validation_data=val, epochs=epochs)\n",
        "except Exception as e: print(e)\n",
        "\n",
        "vgg19_model.save(vgg19_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_yb_-_GUCna"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "epochs_range= range(epochs)\n",
        "\n",
        "plt.plot( epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
        "\n",
        "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend(['train', 'validation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fjuSxMCglJ"
      },
      "source": [
        "## Create Model using MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHkMzA0qCyHJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4Tc2QXKO_Um"
      },
      "outputs": [],
      "source": [
        "mobilenet_model = models.Sequential(name='MobileNet_Model')\n",
        "mobilenet_pretrained_model = tf.keras.applications.MobileNetV2(include_top=False,\n",
        "                   input_shape=input_shape,\n",
        "                   pooling='max',classes=classes,\n",
        "                   weights='imagenet')\n",
        "for each_layer in mobilenet_pretrained_model.layers:\n",
        "        each_layer.trainable=False\n",
        "\n",
        "mobilenet_model.add(mobilenet_pretrained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZSMsRNZO_Un"
      },
      "outputs": [],
      "source": [
        "mobilenet_model.add(layers.Flatten())\n",
        "\n",
        "mobilenet_model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "mobilenet_model.add(layers.Dense(classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqUALV_YO_Uo"
      },
      "outputs": [],
      "source": [
        "mobilenet_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "\n",
        "epochs = 8\n",
        "try:\n",
        "  history = mobilenet_model.fit(train, validation_data=val, epochs=epochs)\n",
        "except Exception as e: print(e)\n",
        "mobilenet_model.save(mobilenet_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZl7Qx1GO_Up"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "epochs_range= range(epochs)\n",
        "\n",
        "plt.plot(epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
        "\n",
        "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
        "\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend(['train', 'validation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsRDtUFKO_Uq"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCJ77WBWO_Uz"
      },
      "outputs": [],
      "source": [
        "# Load trained models from file system\n",
        "models = [models.load_model(custom_model_path),\n",
        "          models.load_model(resnet_model_path),\n",
        "          models.load_model(vgg19_model_path),\n",
        "          models.load_model(mobilenet_model_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFj-1cLGO_Uz"
      },
      "outputs": [],
      "source": [
        "# Create the weighted average ensemble model\n",
        "weights = [0.25, 0.25, 0.25, 0.25]\n",
        "inputs = layers.Input(shape = input_shape)\n",
        "outputs = [model(inputs) for model in models]\n",
        "weighted_average = tf.reshape((), (0, classes)) # An empty tensor\n",
        "\n",
        "for i in range(0, len(models)):\n",
        "    if i == 0:\n",
        "        weighted_average = weights[i] * outputs[i]\n",
        "    else:\n",
        "        weighted_average = weighted_average + weights[i] * outputs[i]\n",
        "    # weighted_average = weighted_average + weights[i] * outputs[i]\n",
        "    # weighted_average = tf.math.add(weighted_average, weights[i] * outputs[i])\n",
        "# weighted_average = weights[0]*outputs[0] + weights[1]*outputs[1] + weights[2]*outputs[2] + weights[3]*outputs[3]\n",
        "\n",
        "ensemble_model = tf.keras.Model(inputs = inputs, outputs = weighted_average, name = 'Ensemble_Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6HPcTghO_U0"
      },
      "outputs": [],
      "source": [
        "ensemble_model.compile(optimizer = optimizers.Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "ensemble_model.save(ensemble_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3lpOe7cO_U0"
      },
      "outputs": [],
      "source": [
        "ensemble_model.evaluate(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byuqLwH3O_U1"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FCjdfb7O_U1"
      },
      "outputs": [],
      "source": [
        "# Testing the ensemble model\n",
        "\n",
        "iterator = test.__iter__()\n",
        "current = iterator.get_next()\n",
        "plt.imshow(current[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhmv0ldHO_U2"
      },
      "outputs": [],
      "source": [
        "ensemble_model_prediction = ensemble_model.predict(current[0])\n",
        "print(ensemble_model_prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXbJzpCzO_U3"
      },
      "outputs": [],
      "source": [
        "custom_model = tf.keras.models.load_model(custom_model_path)\n",
        "custom_model_prediction = custom_model.predict(current[0])\n",
        "print(custom_model_prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IoKY83_O_U3"
      },
      "outputs": [],
      "source": [
        "resnet_model = tf.keras.models.load_model(resnet_model_path)\n",
        "resnet_model_prediction = resnet_model.predict(current[0])\n",
        "print(resnet_model_prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syz50-R1O_U4"
      },
      "outputs": [],
      "source": [
        "vgg19_model = tf.keras.models.load_model(vgg19_model_path)\n",
        "vgg19_model_prediction = vgg19_model.predict(current[0])\n",
        "print(vgg19_model_prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Enj7NCXO_U5"
      },
      "outputs": [],
      "source": [
        "mobilenet_model = tf.keras.models.load_model(mobilenet_model_path)\n",
        "mobilenet_model_prediction = mobilenet_model.predict(current[0])\n",
        "print(mobilenet_model_prediction[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quP5ht2AO_U5"
      },
      "outputs": [],
      "source": [
        "custom_model.evaluate(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQK7C8oqO_U6"
      },
      "outputs": [],
      "source": [
        "mobilenet_model.evaluate(test)\n",
        "resnet_model.evaluate(test)\n",
        "vgg19_model.evaluate(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SHSiL_1JM9o"
      },
      "source": [
        "## Creating a function to classify images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjy6QiFZJQTv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage import transform\n",
        "\n",
        "ensemble_model_path = os.path.join(os.curdir, 'drive', 'MyDrive', 'Muvision', 'models', 'custom_model2.h5')\n",
        "ensemble_model = tf.keras.models.load_model(ensemble_model_path)\n",
        "image_size = (45,45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ-kYEpPJdnR"
      },
      "outputs": [],
      "source": [
        "from skimage import transform\n",
        "from skimage import morphology\n",
        "def classify(np_image):\n",
        "  # np_image = Image.open(filename)\n",
        "  # print(shape(np_image))\n",
        "  #  np_image = tf.image.rgb_to_grayscale(np_image, name='jeff')\n",
        "  # np_image = cv.cvtColor(image, cv.COLOR_RGBA2RGB)\n",
        "  np_image = np.array(np_image).astype('float32')/256\n",
        "  np_image = transform.resize(np_image, (45, 45,3))\n",
        "  imgplot = plt.imshow(np_image)\n",
        "  plt.show()\n",
        "  np_image = np.expand_dims(np_image, axis=0)\n",
        "  prediction = ensemble_model.predict(np_image)\n",
        "  # class_order = ['!', '(', ')', '+', 'forward_slash', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '=', 'A', 'C', 'Delta', 'G', 'H', 'M', 'N', 'R', 'S', 'T', 'X', '[', ']', 'alpha', 'ascii_124', 'b', 'beta', 'cos', 'd', 'div', 'e', 'exists', 'f', 'forall', 'forward_slash', 'gamma', 'geq', 'gt', 'i', 'in', 'infty', 'int', 'j', 'k', 'l', 'lambda', 'ldots', 'leq', 'lim', 'log', 'lt', 'mu', 'neq', 'o', 'p', 'phi', 'pi', 'pm', 'prime', 'q', 'rightarrow', 'sigma', 'sin', 'sqrt', 'sum', 'tan', 'theta', 'times', 'u', 'v', 'w', 'y', 'z', '{', '}']\n",
        "  class_order = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '.', '\\\\div', '=', '\\\\times', '-', 'x', 'y', 'z']\n",
        "  return np.argmax(prediction)\n",
        "  res = tf.math.argmax(prediction[0])\n",
        "  # return int(tensor)\n",
        "  return class_order[int(tensor)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0vfUKgeM-oC"
      },
      "outputs": [],
      "source": [
        "sample_img_name = os.path.join(os.curdir, 'drive', 'MyDrive', 'Muvision', 'sample_img', 'x.png')\n",
        "image = Image.open(sample_img_name)\n",
        "print(image)\n",
        "print(classify(image))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "toc-autonumbering": false,
    "toc-showmarkdowntxt": true,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}